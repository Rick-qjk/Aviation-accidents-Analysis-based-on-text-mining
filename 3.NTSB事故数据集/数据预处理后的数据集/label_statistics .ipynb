{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('.\\\\inputs_clean.xlsx')\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels=[ list(eval(row['category_abbr'])) for index,row in df.iterrows()]\n",
    "binary_matrix= mlb.fit_transform(labels)\n",
    "encoded_labels = mlb.fit_transform(labels).tolist()\n",
    "df['target_list']=encoded_labels\n",
    "df_final = df[['clean_text','target_list']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = {label: sum(row) for label, row in zip(mlb.classes_, binary_matrix.T)}\n",
    "l=mlb.classes_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标签：CTOL, 数量：8897, 百分比：23.81%\n",
      "标签：RE, 数量：4934, 百分比：13.20%\n",
      "标签：ARC, 数量：3883, 百分比：10.39%\n",
      "标签：LOC-I, 数量：3857, 百分比：10.32%\n",
      "标签：SCF-PP, 数量：3602, 百分比：9.64%\n",
      "标签：LOC-G, 数量：3464, 百分比：9.27%\n",
      "标签：FUEL, 数量：1251, 百分比：3.35%\n",
      "标签：OTHERS, 数量：1129, 百分比：3.02%\n",
      "标签：SCF-NP, 数量：1108, 百分比：2.96%\n",
      "标签：CFIT, 数量：633, 百分比：1.69%\n",
      "标签：UIMC, 数量：466, 百分比：1.25%\n",
      "标签：GCOL, 数量：454, 百分比：1.21%\n",
      "标签：RAMP, 数量：442, 百分比：1.18%\n",
      "标签：LALT, 数量：408, 百分比：1.09%\n",
      "标签：USOS, 数量：407, 百分比：1.09%\n",
      "标签：F-POST, 数量：281, 百分比：0.75%\n",
      "标签：AMAN, 数量：264, 百分比：0.71%\n",
      "标签：MAC, 数量：258, 百分比：0.69%\n",
      "标签：TURB, 数量：248, 百分比：0.66%\n",
      "标签：F-NI, 数量：237, 百分比：0.63%\n",
      "标签：LOLI, 数量：194, 百分比：0.52%\n",
      "标签：EVAC, 数量：146, 百分比：0.39%\n",
      "标签：WSTRW, 数量：146, 百分比：0.39%\n",
      "标签：BIRD, 数量：129, 百分比：0.35%\n",
      "标签：CABIN, 数量：110, 百分比：0.29%\n",
      "标签：EXTL, 数量：88, 百分比：0.24%\n",
      "标签：ATM, 数量：68, 百分比：0.18%\n",
      "标签：ICE, 数量：68, 百分比：0.18%\n",
      "标签：WILD, 数量：55, 百分比：0.15%\n",
      "标签：RI, 数量：49, 百分比：0.13%\n",
      "标签：GTOW, 数量：38, 百分比：0.10%\n",
      "标签：ADRM, 数量：34, 百分比：0.09%\n",
      "标签：SEC, 数量：13, 百分比：0.03%\n",
      "标签：UNK, 数量：9, 百分比：0.02%\n"
     ]
    }
   ],
   "source": [
    "total_labels = binary_matrix.sum()\n",
    "label_counts = binary_matrix.sum(axis=0)\n",
    "label_percentages = (label_counts / total_labels) * 100\n",
    "label_details = list(zip(mlb.classes_, label_counts, label_percentages))\n",
    "label_details.sort(key=lambda x: x[1], reverse=True)\n",
    "for label, count, percentage in label_details:\n",
    "    print(f\"标签：{label}, 数量：{count}, 百分比：{percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_list(L):\n",
    "    n = len(L)\n",
    "    part_size = n // 6\n",
    "    remainder = n % 6\n",
    "    parts = []\n",
    "    start = 0\n",
    "\n",
    "    for i in range(6):\n",
    "        end = start + part_size + (1 if i < remainder else 0)\n",
    "        parts.append(L[start:end])\n",
    "        start = end\n",
    "\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_aug=[i[0] for i in label_details]\n",
    "l=divide_list(label_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_need=l[0]\n",
    "need_3=l[1]\n",
    "need_5=l[2]\n",
    "need_7=l[3]\n",
    "need_10=l[4]\n",
    "need_15=l[5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splite(df,lst):\n",
    "    judge=[]\n",
    "    for index,row in df.iterrows():\n",
    "        t=eval(row['factor_list'])\n",
    "        for i in lst:\n",
    "            if i in t:\n",
    "                judge.append(1)\n",
    "                break\n",
    "            if i==lst[-1]:\n",
    "                judge.append(0)\n",
    "    df['judge']=judge\n",
    "    df_f=df[df['judge']==1]\n",
    "    df_ff= df_f[['clean_text','target_list']].copy()\n",
    "    return  df_ff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_need3=get_splite(df,need_3)\n",
    "df_need5=get_splite(df,need_5)\n",
    "df_need7=get_splite(df,need_7)\n",
    "df_need10=get_splite(df,need_10)\n",
    "df_need15=get_splite(df,need_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>target_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the pilot wife stated that the airplane engine...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the pilot attempted a simulated forced landing...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the pilot stated that she had executed four fu...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the pilot reported that during the takeoff rol...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the two commercial pilots one of whom was a fl...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13573</th>\n",
       "      <td>the pilot stated that while taxiing the airpla...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13574</th>\n",
       "      <td>the student pilot flared early and bounced the...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13577</th>\n",
       "      <td>the pilot was on a cross-country flight and no...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13578</th>\n",
       "      <td>on the day of the accident the pilot reported ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13579</th>\n",
       "      <td>the pilot reported that during the landing rol...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11670 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              clean_text  \\\n",
       "0      the pilot wife stated that the airplane engine...   \n",
       "1      the pilot attempted a simulated forced landing...   \n",
       "2      the pilot stated that she had executed four fu...   \n",
       "3      the pilot reported that during the takeoff rol...   \n",
       "5      the two commercial pilots one of whom was a fl...   \n",
       "...                                                  ...   \n",
       "13573  the pilot stated that while taxiing the airpla...   \n",
       "13574  the student pilot flared early and bounced the...   \n",
       "13577  the pilot was on a cross-country flight and no...   \n",
       "13578  on the day of the accident the pilot reported ...   \n",
       "13579  the pilot reported that during the landing rol...   \n",
       "\n",
       "                                             target_list  \n",
       "0      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "2      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "3      [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "5      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                  ...  \n",
       "13573  [0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "13574  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "13577  [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "13578  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "13579  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[11670 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_need=get_splite(df,no_need)\n",
    "df_no_need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Rick\n",
      "[nltk_data]     Qin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from itertools import chain\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def synonym_replacement(sentence, n=1):\n",
    "    words = sentence.split()\n",
    "    new_words = words.copy()\n",
    "\n",
    "    for _ in range(n):\n",
    "        word_to_replace = random.choice(words)\n",
    "        synonyms = wordnet.synsets(word_to_replace)\n",
    "\n",
    "        if synonyms:\n",
    "            synonym_words = set(chain.from_iterable([syn.lemma_names() for syn in synonyms]))\n",
    "            synonym_words.discard(word_to_replace)  # 删除原词\n",
    "            if synonym_words:\n",
    "                synonym_word = random.choice(list(synonym_words))\n",
    "                new_words[new_words.index(word_to_replace)] = synonym_word\n",
    "\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "\n",
    "def random_insertion(sentence, n=1):\n",
    "    words = sentence.split()\n",
    "    for _ in range(n):\n",
    "        word_to_insert = random.choice(words)\n",
    "        synonyms = wordnet.synsets(word_to_insert)\n",
    "\n",
    "        if synonyms:\n",
    "            synonym_words = set(chain.from_iterable([syn.lemma_names() for syn in synonyms]))\n",
    "            if synonym_words:\n",
    "                new_word = random.choice(list(synonym_words))\n",
    "                insert_position = random.randint(0, len(words))\n",
    "                words.insert(insert_position, new_word)\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "def random_deletion(sentence, p=0.5):\n",
    "    words = sentence.split()\n",
    "    if len(words) == 1: \n",
    "        return sentence\n",
    "    remaining_words = [word for word in words if random.random() > p]\n",
    "    return ' '.join(remaining_words) if remaining_words else random.choice(words)\n",
    "\n",
    "\n",
    "def random_swap(sentence, n=1):\n",
    "    words = sentence.split()\n",
    "    for _ in range(n):\n",
    "        idx1, idx2 = random.sample(range(len(words)), 2)\n",
    "        words[idx1], words[idx2] = words[idx2], words[idx1]\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "def augment_text(sentence, n_synonyms=1, n_insertions=1, p_deletion=0.5, n_swaps=1):\n",
    "    sentence = synonym_replacement(sentence, n=n_synonyms)\n",
    "    sentence = random_insertion(sentence, n=n_insertions)\n",
    "    sentence = random_deletion(sentence, p=p_deletion)\n",
    "    sentence = random_swap(sentence, n=n_swaps)\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_dataframe(df, text_column='clean_text', target_column='target_list', augment_times=1):\n",
    "    augmented_texts = []\n",
    "    target_labels = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        text = row[text_column]\n",
    "        label = row[target_column]\n",
    "        \n",
    "        \n",
    "        augmented_texts.append(text)\n",
    "        target_labels.append(label)\n",
    "        \n",
    "        \n",
    "        for _ in range(augment_times):\n",
    "            augmented_text = augment_text(text)\n",
    "            augmented_texts.append(augmented_text)\n",
    "            target_labels.append(label)\n",
    "    \n",
    "\n",
    "    augmented_df = pd.DataFrame({\n",
    "        text_column: augmented_texts,\n",
    "        target_column: target_labels\n",
    "    })\n",
    "    \n",
    "    return augmented_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_augmented_need3 = augment_dataframe(df_need3, text_column='clean_text', target_column='target_list', augment_times=2)\n",
    "df_augmented_need5=augment_dataframe(df_need5, text_column='clean_text', target_column='target_list', augment_times=4)\n",
    "df_augmented_need7=augment_dataframe(df_need7, text_column='clean_text', target_column='target_list', augment_times=6)\n",
    "df_augmented_need10=augment_dataframe(df_need10, text_column='clean_text', target_column='target_list', augment_times=9)\n",
    "df_augmented_need15=augment_dataframe(df_need15, text_column='clean_text', target_column='target_list', augment_times=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concatenated = pd.concat([df_no_need,df_augmented_need3,df_augmented_need5,df_augmented_need7,df_augmented_need10,df_augmented_need15], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concatenated.to_excel('inputs_augment_new_factor.xlsx',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
